{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-12-12T12:45:30.247393Z",
     "start_time": "2023-12-12T12:45:28.159359Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/12/12 13:45:29 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "data": {
      "text/plain": "<pyspark.sql.session.SparkSession at 0x105ed5ee0>",
      "text/html": "\n            <div>\n                <p><b>SparkSession - in-memory</b></p>\n                \n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"http://192.168.8.147:4040\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v3.5.0</code></dd>\n              <dt>Master</dt>\n                <dd><code>local[*]</code></dd>\n              <dt>AppName</dt>\n                <dd><code>Meteo</code></dd>\n            </dl>\n        </div>\n        \n            </div>\n        "
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName('Meteo').getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "spark.conf.set('spark.sql.repl.eagerEval.enabled', True) "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T12:45:35.564183Z",
     "start_time": "2023-12-12T12:45:35.549885Z"
    }
   },
   "id": "e55ae53f0eee7ded"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Wczytanie pliku csv\n",
    "df_spark = spark.read.csv('open-meteo-52.52N13.42E38m.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T12:46:01.781243Z",
     "start_time": "2023-12-12T12:45:59.754411Z"
    }
   },
   "id": "f701c69350d3b934"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+--------------+\n",
      "|       _c0|  _c1|           _c2|\n",
      "+----------+-----+--------------+\n",
      "|      date| time|temperature_2m|\n",
      "|2023-12-12|00:00|           7.0|\n",
      "|2023-12-12|01:00|           6.8|\n",
      "|2023-12-12|02:00|           6.4|\n",
      "|2023-12-12|03:00|           6.3|\n",
      "|2023-12-12|04:00|           6.1|\n",
      "|2023-12-12|05:00|           6.0|\n",
      "|2023-12-12|06:00|           6.0|\n",
      "|2023-12-12|07:00|           5.9|\n",
      "|2023-12-12|08:00|          NULL|\n",
      "|      NULL| NULL|           6.1|\n",
      "|2023-12-12|10:00|           6.1|\n",
      "|      NULL| NULL|          NULL|\n",
      "|2023-12-12|12:00|           6.5|\n",
      "|2023-12-12|13:00|           6.7|\n",
      "|2023-12-12|14:00|           6.7|\n",
      "|2023-12-12|15:00|           6.5|\n",
      "|2023-12-12|16:00|           6.1|\n",
      "|2023-12-12|17:00|           5.7|\n",
      "|2023-12-12|18:00|           5.2|\n",
      "+----------+-----+--------------+\n"
     ]
    }
   ],
   "source": [
    "df_spark.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T12:46:04.379299Z",
     "start_time": "2023-12-12T12:46:04.287717Z"
    }
   },
   "id": "8e4745043f00f86e"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "+----------+-------------------+--------------+\n|      date|               time|temperature_2m|\n+----------+-------------------+--------------+\n|2023-12-12|2023-12-12 00:00:00|           7.0|\n|2023-12-12|2023-12-12 01:00:00|           6.8|\n|2023-12-12|2023-12-12 02:00:00|           6.4|\n|2023-12-12|2023-12-12 03:00:00|           6.3|\n|2023-12-12|2023-12-12 04:00:00|           6.1|\n|2023-12-12|2023-12-12 05:00:00|           6.0|\n|2023-12-12|2023-12-12 06:00:00|           6.0|\n|2023-12-12|2023-12-12 07:00:00|           5.9|\n|2023-12-12|2023-12-12 08:00:00|          NULL|\n|      NULL|               NULL|           6.1|\n|2023-12-12|2023-12-12 10:00:00|           6.1|\n|      NULL|               NULL|          NULL|\n|2023-12-12|2023-12-12 12:00:00|           6.5|\n|2023-12-12|2023-12-12 13:00:00|           6.7|\n|2023-12-12|2023-12-12 14:00:00|           6.7|\n|2023-12-12|2023-12-12 15:00:00|           6.5|\n|2023-12-12|2023-12-12 16:00:00|           6.1|\n|2023-12-12|2023-12-12 17:00:00|           5.7|\n|2023-12-12|2023-12-12 18:00:00|           5.2|\n|2023-12-12|2023-12-12 19:00:00|           4.5|\n+----------+-------------------+--------------+\nonly showing top 20 rows",
      "text/html": "<table border='1'>\n<tr><th>date</th><th>time</th><th>temperature_2m</th></tr>\n<tr><td>2023-12-12</td><td>2023-12-12 00:00:00</td><td>7.0</td></tr>\n<tr><td>2023-12-12</td><td>2023-12-12 01:00:00</td><td>6.8</td></tr>\n<tr><td>2023-12-12</td><td>2023-12-12 02:00:00</td><td>6.4</td></tr>\n<tr><td>2023-12-12</td><td>2023-12-12 03:00:00</td><td>6.3</td></tr>\n<tr><td>2023-12-12</td><td>2023-12-12 04:00:00</td><td>6.1</td></tr>\n<tr><td>2023-12-12</td><td>2023-12-12 05:00:00</td><td>6.0</td></tr>\n<tr><td>2023-12-12</td><td>2023-12-12 06:00:00</td><td>6.0</td></tr>\n<tr><td>2023-12-12</td><td>2023-12-12 07:00:00</td><td>5.9</td></tr>\n<tr><td>2023-12-12</td><td>2023-12-12 08:00:00</td><td>NULL</td></tr>\n<tr><td>NULL</td><td>NULL</td><td>6.1</td></tr>\n<tr><td>2023-12-12</td><td>2023-12-12 10:00:00</td><td>6.1</td></tr>\n<tr><td>NULL</td><td>NULL</td><td>NULL</td></tr>\n<tr><td>2023-12-12</td><td>2023-12-12 12:00:00</td><td>6.5</td></tr>\n<tr><td>2023-12-12</td><td>2023-12-12 13:00:00</td><td>6.7</td></tr>\n<tr><td>2023-12-12</td><td>2023-12-12 14:00:00</td><td>6.7</td></tr>\n<tr><td>2023-12-12</td><td>2023-12-12 15:00:00</td><td>6.5</td></tr>\n<tr><td>2023-12-12</td><td>2023-12-12 16:00:00</td><td>6.1</td></tr>\n<tr><td>2023-12-12</td><td>2023-12-12 17:00:00</td><td>5.7</td></tr>\n<tr><td>2023-12-12</td><td>2023-12-12 18:00:00</td><td>5.2</td></tr>\n<tr><td>2023-12-12</td><td>2023-12-12 19:00:00</td><td>4.5</td></tr>\n</table>\nonly showing top 20 rows\n"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inferSchema=True zmienia string na typy danych\n",
    "\n",
    "df_spark = spark.read.option('header', 'true').csv('open-meteo-52.52N13.42E38m.csv', inferSchema=True)\n",
    "df_spark"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T12:47:17.827139Z",
     "start_time": "2023-12-12T12:47:17.512831Z"
    }
   },
   "id": "9689f8e39d5618d0"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------------+--------------+\n",
      "|      date|               time|temperature_2m|\n",
      "+----------+-------------------+--------------+\n",
      "|2023-12-12|2023-12-12 00:00:00|           7.0|\n",
      "|2023-12-12|2023-12-12 01:00:00|           6.8|\n",
      "|2023-12-12|2023-12-12 02:00:00|           6.4|\n",
      "|2023-12-12|2023-12-12 03:00:00|           6.3|\n",
      "|2023-12-12|2023-12-12 04:00:00|           6.1|\n",
      "|2023-12-12|2023-12-12 05:00:00|           6.0|\n",
      "|2023-12-12|2023-12-12 06:00:00|           6.0|\n",
      "|2023-12-12|2023-12-12 07:00:00|           5.9|\n",
      "|2023-12-12|2023-12-12 08:00:00|          NULL|\n",
      "|      NULL|               NULL|           6.1|\n",
      "|2023-12-12|2023-12-12 10:00:00|           6.1|\n",
      "|      NULL|               NULL|          NULL|\n",
      "|2023-12-12|2023-12-12 12:00:00|           6.5|\n",
      "|2023-12-12|2023-12-12 13:00:00|           6.7|\n",
      "|2023-12-12|2023-12-12 14:00:00|           6.7|\n",
      "|2023-12-12|2023-12-12 15:00:00|           6.5|\n",
      "|2023-12-12|2023-12-12 16:00:00|           6.1|\n",
      "|2023-12-12|2023-12-12 17:00:00|           5.7|\n",
      "|2023-12-12|2023-12-12 18:00:00|           5.2|\n",
      "|2023-12-12|2023-12-12 19:00:00|           4.5|\n",
      "+----------+-------------------+--------------+\n"
     ]
    }
   ],
   "source": [
    "df_spark.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T12:47:21.705027Z",
     "start_time": "2023-12-12T12:47:21.636299Z"
    }
   },
   "id": "6e16c9846e3c4faf"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "pyspark.sql.dataframe.DataFrame"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_spark)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T12:47:27.740613Z",
     "start_time": "2023-12-12T12:47:27.728882Z"
    }
   },
   "id": "d26fc171a5f2f43b"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "[Row(date=datetime.date(2023, 12, 12), time=datetime.datetime(2023, 12, 12, 0, 0), temperature_2m=7.0),\n Row(date=datetime.date(2023, 12, 12), time=datetime.datetime(2023, 12, 12, 1, 0), temperature_2m=6.8),\n Row(date=datetime.date(2023, 12, 12), time=datetime.datetime(2023, 12, 12, 2, 0), temperature_2m=6.4)]"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spark.head(3)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T12:47:42.272923Z",
     "start_time": "2023-12-12T12:47:42.188232Z"
    }
   },
   "id": "a3d1007294f7e2b7"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- date: date (nullable = true)\n",
      " |-- time: timestamp (nullable = true)\n",
      " |-- temperature_2m: double (nullable = true)\n"
     ]
    }
   ],
   "source": [
    "# schema\n",
    "df_spark.printSchema()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T12:47:47.898971Z",
     "start_time": "2023-12-12T12:47:47.885047Z"
    }
   },
   "id": "6b0d917a8e66a461"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "['date', 'time', 'temperature_2m']"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spark.columns"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T12:47:53.359541Z",
     "start_time": "2023-12-12T12:47:53.351847Z"
    }
   },
   "id": "73f55c8038d835a4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Wybór kolumny"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "420d8a1d103af5a5"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|      date|\n",
      "+----------+\n",
      "|2023-12-12|\n",
      "|2023-12-12|\n",
      "|2023-12-12|\n",
      "|2023-12-12|\n",
      "|2023-12-12|\n",
      "|2023-12-12|\n",
      "|2023-12-12|\n",
      "|2023-12-12|\n",
      "|2023-12-12|\n",
      "|      NULL|\n",
      "|2023-12-12|\n",
      "|      NULL|\n",
      "|2023-12-12|\n",
      "|2023-12-12|\n",
      "|2023-12-12|\n",
      "|2023-12-12|\n",
      "|2023-12-12|\n",
      "|2023-12-12|\n",
      "|2023-12-12|\n",
      "|2023-12-12|\n",
      "+----------+\n"
     ]
    }
   ],
   "source": [
    "df_spark.select('date').show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T12:48:16.179940Z",
     "start_time": "2023-12-12T12:48:16.077787Z"
    }
   },
   "id": "a70991e2d3bf4447"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "pyspark.sql.dataframe.DataFrame"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_spark.select('time'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T12:48:23.052662Z",
     "start_time": "2023-12-12T12:48:23.033691Z"
    }
   },
   "id": "977d74e871dacaef"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------+\n",
      "|      date|temperature_2m|\n",
      "+----------+--------------+\n",
      "|2023-12-12|           7.0|\n",
      "|2023-12-12|           6.8|\n",
      "|2023-12-12|           6.4|\n",
      "|2023-12-12|           6.3|\n",
      "|2023-12-12|           6.1|\n",
      "|2023-12-12|           6.0|\n",
      "|2023-12-12|           6.0|\n",
      "|2023-12-12|           5.9|\n",
      "|2023-12-12|          NULL|\n",
      "|      NULL|           6.1|\n",
      "|2023-12-12|           6.1|\n",
      "|      NULL|          NULL|\n",
      "|2023-12-12|           6.5|\n",
      "|2023-12-12|           6.7|\n",
      "|2023-12-12|           6.7|\n",
      "|2023-12-12|           6.5|\n",
      "|2023-12-12|           6.1|\n",
      "|2023-12-12|           5.7|\n",
      "|2023-12-12|           5.2|\n",
      "|2023-12-12|           4.5|\n",
      "+----------+--------------+\n"
     ]
    }
   ],
   "source": [
    "df_spark.select(['date', 'temperature_2m']).show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T12:48:40.114169Z",
     "start_time": "2023-12-12T12:48:40.021375Z"
    }
   },
   "id": "f98632450aea7276"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "pyspark.sql.dataframe.DataFrame"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_spark.select(['date', 'temperature_2m']))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T12:48:44.785534Z",
     "start_time": "2023-12-12T12:48:44.768225Z"
    }
   },
   "id": "ff33399a46a72276"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Column' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[16], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m df_spark[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdate\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[0;32m----> 2\u001B[0m df_spark[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdate\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mshow()\n",
      "\u001B[0;31mTypeError\u001B[0m: 'Column' object is not callable"
     ]
    }
   ],
   "source": [
    "df_spark['date']\n",
    "# df_spark['date'].show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T12:49:07.837870Z",
     "start_time": "2023-12-12T12:49:07.586744Z"
    }
   },
   "id": "1707922178a599ff"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "[('date', 'date'), ('time', 'timestamp'), ('temperature_2m', 'double')]"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spark.dtypes"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T12:49:19.795524Z",
     "start_time": "2023-12-12T12:49:19.779478Z"
    }
   },
   "id": "9b7470437f41e5ea"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+\n",
      "|summary|   temperature_2m|\n",
      "+-------+-----------------+\n",
      "|  count|              166|\n",
      "|   mean| 5.23132530120482|\n",
      "| stddev|2.512172919682535|\n",
      "|    min|              0.2|\n",
      "|    max|              9.5|\n",
      "+-------+-----------------+\n"
     ]
    }
   ],
   "source": [
    "df_spark.describe().show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T12:50:17.121215Z",
     "start_time": "2023-12-12T12:50:16.771016Z"
    }
   },
   "id": "1f4910668ed59b7e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Dodawanie kolumny"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "37f363c14b0ee82b"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "+----------+-------------------+--------------+--------------------------+\n|      date|               time|temperature_2m|Temperature rise 2 degrees|\n+----------+-------------------+--------------+--------------------------+\n|2023-12-12|2023-12-12 00:00:00|           7.0|                       9.0|\n|2023-12-12|2023-12-12 01:00:00|           6.8|                       8.8|\n|2023-12-12|2023-12-12 02:00:00|           6.4|                       8.4|\n|2023-12-12|2023-12-12 03:00:00|           6.3|                       8.3|\n|2023-12-12|2023-12-12 04:00:00|           6.1|                       8.1|\n|2023-12-12|2023-12-12 05:00:00|           6.0|                       8.0|\n|2023-12-12|2023-12-12 06:00:00|           6.0|                       8.0|\n|2023-12-12|2023-12-12 07:00:00|           5.9|                       7.9|\n|2023-12-12|2023-12-12 08:00:00|          NULL|                      NULL|\n|      NULL|               NULL|           6.1|                       8.1|\n|2023-12-12|2023-12-12 10:00:00|           6.1|                       8.1|\n|      NULL|               NULL|          NULL|                      NULL|\n|2023-12-12|2023-12-12 12:00:00|           6.5|                       8.5|\n|2023-12-12|2023-12-12 13:00:00|           6.7|                       8.7|\n|2023-12-12|2023-12-12 14:00:00|           6.7|                       8.7|\n|2023-12-12|2023-12-12 15:00:00|           6.5|                       8.5|\n|2023-12-12|2023-12-12 16:00:00|           6.1|                       8.1|\n|2023-12-12|2023-12-12 17:00:00|           5.7|                       7.7|\n|2023-12-12|2023-12-12 18:00:00|           5.2|                       7.2|\n|2023-12-12|2023-12-12 19:00:00|           4.5|                       6.5|\n+----------+-------------------+--------------+--------------------------+\nonly showing top 20 rows",
      "text/html": "<table border='1'>\n<tr><th>date</th><th>time</th><th>temperature_2m</th><th>Temperature rise 2 degrees</th></tr>\n<tr><td>2023-12-12</td><td>2023-12-12 00:00:00</td><td>7.0</td><td>9.0</td></tr>\n<tr><td>2023-12-12</td><td>2023-12-12 01:00:00</td><td>6.8</td><td>8.8</td></tr>\n<tr><td>2023-12-12</td><td>2023-12-12 02:00:00</td><td>6.4</td><td>8.4</td></tr>\n<tr><td>2023-12-12</td><td>2023-12-12 03:00:00</td><td>6.3</td><td>8.3</td></tr>\n<tr><td>2023-12-12</td><td>2023-12-12 04:00:00</td><td>6.1</td><td>8.1</td></tr>\n<tr><td>2023-12-12</td><td>2023-12-12 05:00:00</td><td>6.0</td><td>8.0</td></tr>\n<tr><td>2023-12-12</td><td>2023-12-12 06:00:00</td><td>6.0</td><td>8.0</td></tr>\n<tr><td>2023-12-12</td><td>2023-12-12 07:00:00</td><td>5.9</td><td>7.9</td></tr>\n<tr><td>2023-12-12</td><td>2023-12-12 08:00:00</td><td>NULL</td><td>NULL</td></tr>\n<tr><td>NULL</td><td>NULL</td><td>6.1</td><td>8.1</td></tr>\n<tr><td>2023-12-12</td><td>2023-12-12 10:00:00</td><td>6.1</td><td>8.1</td></tr>\n<tr><td>NULL</td><td>NULL</td><td>NULL</td><td>NULL</td></tr>\n<tr><td>2023-12-12</td><td>2023-12-12 12:00:00</td><td>6.5</td><td>8.5</td></tr>\n<tr><td>2023-12-12</td><td>2023-12-12 13:00:00</td><td>6.7</td><td>8.7</td></tr>\n<tr><td>2023-12-12</td><td>2023-12-12 14:00:00</td><td>6.7</td><td>8.7</td></tr>\n<tr><td>2023-12-12</td><td>2023-12-12 15:00:00</td><td>6.5</td><td>8.5</td></tr>\n<tr><td>2023-12-12</td><td>2023-12-12 16:00:00</td><td>6.1</td><td>8.1</td></tr>\n<tr><td>2023-12-12</td><td>2023-12-12 17:00:00</td><td>5.7</td><td>7.7</td></tr>\n<tr><td>2023-12-12</td><td>2023-12-12 18:00:00</td><td>5.2</td><td>7.2</td></tr>\n<tr><td>2023-12-12</td><td>2023-12-12 19:00:00</td><td>4.5</td><td>6.5</td></tr>\n</table>\nonly showing top 20 rows\n"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spark.withColumn('Temperature rise 2 degrees', df_spark['temperature_2m'] + 2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T12:50:58.735548Z",
     "start_time": "2023-12-12T12:50:58.596957Z"
    }
   },
   "id": "33473f2e08f24cfd"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------------+--------------+\n",
      "|      date|               time|temperature_2m|\n",
      "+----------+-------------------+--------------+\n",
      "|2023-12-12|2023-12-12 00:00:00|           7.0|\n",
      "|2023-12-12|2023-12-12 01:00:00|           6.8|\n",
      "|2023-12-12|2023-12-12 02:00:00|           6.4|\n",
      "|2023-12-12|2023-12-12 03:00:00|           6.3|\n",
      "|2023-12-12|2023-12-12 04:00:00|           6.1|\n",
      "|2023-12-12|2023-12-12 05:00:00|           6.0|\n",
      "|2023-12-12|2023-12-12 06:00:00|           6.0|\n",
      "|2023-12-12|2023-12-12 07:00:00|           5.9|\n",
      "|2023-12-12|2023-12-12 08:00:00|          NULL|\n",
      "|      NULL|               NULL|           6.1|\n",
      "|2023-12-12|2023-12-12 10:00:00|           6.1|\n",
      "|      NULL|               NULL|          NULL|\n",
      "|2023-12-12|2023-12-12 12:00:00|           6.5|\n",
      "|2023-12-12|2023-12-12 13:00:00|           6.7|\n",
      "|2023-12-12|2023-12-12 14:00:00|           6.7|\n",
      "|2023-12-12|2023-12-12 15:00:00|           6.5|\n",
      "|2023-12-12|2023-12-12 16:00:00|           6.1|\n",
      "|2023-12-12|2023-12-12 17:00:00|           5.7|\n",
      "|2023-12-12|2023-12-12 18:00:00|           5.2|\n",
      "|2023-12-12|2023-12-12 19:00:00|           4.5|\n",
      "+----------+-------------------+--------------+\n"
     ]
    }
   ],
   "source": [
    "df_spark.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T12:51:03.043838Z",
     "start_time": "2023-12-12T12:51:02.967800Z"
    }
   },
   "id": "f5bbeb01b8775150"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------------+--------------+--------------------------+\n",
      "|      date|               time|temperature_2m|Temperature rise 2 degrees|\n",
      "+----------+-------------------+--------------+--------------------------+\n",
      "|2023-12-12|2023-12-12 00:00:00|           7.0|                       9.0|\n",
      "|2023-12-12|2023-12-12 01:00:00|           6.8|                       8.8|\n",
      "|2023-12-12|2023-12-12 02:00:00|           6.4|                       8.4|\n",
      "|2023-12-12|2023-12-12 03:00:00|           6.3|                       8.3|\n",
      "|2023-12-12|2023-12-12 04:00:00|           6.1|                       8.1|\n",
      "|2023-12-12|2023-12-12 05:00:00|           6.0|                       8.0|\n",
      "|2023-12-12|2023-12-12 06:00:00|           6.0|                       8.0|\n",
      "|2023-12-12|2023-12-12 07:00:00|           5.9|                       7.9|\n",
      "|2023-12-12|2023-12-12 08:00:00|          NULL|                      NULL|\n",
      "|      NULL|               NULL|           6.1|                       8.1|\n",
      "|2023-12-12|2023-12-12 10:00:00|           6.1|                       8.1|\n",
      "|      NULL|               NULL|          NULL|                      NULL|\n",
      "|2023-12-12|2023-12-12 12:00:00|           6.5|                       8.5|\n",
      "|2023-12-12|2023-12-12 13:00:00|           6.7|                       8.7|\n",
      "|2023-12-12|2023-12-12 14:00:00|           6.7|                       8.7|\n",
      "|2023-12-12|2023-12-12 15:00:00|           6.5|                       8.5|\n",
      "|2023-12-12|2023-12-12 16:00:00|           6.1|                       8.1|\n",
      "|2023-12-12|2023-12-12 17:00:00|           5.7|                       7.7|\n",
      "|2023-12-12|2023-12-12 18:00:00|           5.2|                       7.2|\n",
      "|2023-12-12|2023-12-12 19:00:00|           4.5|                       6.5|\n",
      "+----------+-------------------+--------------+--------------------------+\n"
     ]
    }
   ],
   "source": [
    "df_spark = df_spark.withColumn('Temperature rise 2 degrees', df_spark['temperature_2m'] + 2)\n",
    "df_spark.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T12:51:33.767831Z",
     "start_time": "2023-12-12T12:51:33.699323Z"
    }
   },
   "id": "497e1e1f45ae977f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Usuwanie kolumny"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a220466e79ed97c9"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------------+--------------+--------------------------+\n",
      "|      date|               time|temperature_2m|Temperature rise 2 degrees|\n",
      "+----------+-------------------+--------------+--------------------------+\n",
      "|2023-12-12|2023-12-12 00:00:00|           7.0|                       9.0|\n",
      "|2023-12-12|2023-12-12 01:00:00|           6.8|                       8.8|\n",
      "|2023-12-12|2023-12-12 02:00:00|           6.4|                       8.4|\n",
      "|2023-12-12|2023-12-12 03:00:00|           6.3|                       8.3|\n",
      "|2023-12-12|2023-12-12 04:00:00|           6.1|                       8.1|\n",
      "|2023-12-12|2023-12-12 05:00:00|           6.0|                       8.0|\n",
      "|2023-12-12|2023-12-12 06:00:00|           6.0|                       8.0|\n",
      "|2023-12-12|2023-12-12 07:00:00|           5.9|                       7.9|\n",
      "|2023-12-12|2023-12-12 08:00:00|          NULL|                      NULL|\n",
      "|      NULL|               NULL|           6.1|                       8.1|\n",
      "|2023-12-12|2023-12-12 10:00:00|           6.1|                       8.1|\n",
      "|      NULL|               NULL|          NULL|                      NULL|\n",
      "|2023-12-12|2023-12-12 12:00:00|           6.5|                       8.5|\n",
      "|2023-12-12|2023-12-12 13:00:00|           6.7|                       8.7|\n",
      "|2023-12-12|2023-12-12 14:00:00|           6.7|                       8.7|\n",
      "|2023-12-12|2023-12-12 15:00:00|           6.5|                       8.5|\n",
      "|2023-12-12|2023-12-12 16:00:00|           6.1|                       8.1|\n",
      "|2023-12-12|2023-12-12 17:00:00|           5.7|                       7.7|\n",
      "|2023-12-12|2023-12-12 18:00:00|           5.2|                       7.2|\n",
      "|2023-12-12|2023-12-12 19:00:00|           4.5|                       6.5|\n",
      "+----------+-------------------+--------------+--------------------------+\n"
     ]
    }
   ],
   "source": [
    "df_spark.drop('Temperature rise 2 degrees')\n",
    "df_spark.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T12:52:04.914745Z",
     "start_time": "2023-12-12T12:52:04.848035Z"
    }
   },
   "id": "2be5b6830839797"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------------+--------------+\n",
      "|      date|               time|temperature_2m|\n",
      "+----------+-------------------+--------------+\n",
      "|2023-12-12|2023-12-12 00:00:00|           7.0|\n",
      "|2023-12-12|2023-12-12 01:00:00|           6.8|\n",
      "|2023-12-12|2023-12-12 02:00:00|           6.4|\n",
      "|2023-12-12|2023-12-12 03:00:00|           6.3|\n",
      "|2023-12-12|2023-12-12 04:00:00|           6.1|\n",
      "|2023-12-12|2023-12-12 05:00:00|           6.0|\n",
      "|2023-12-12|2023-12-12 06:00:00|           6.0|\n",
      "|2023-12-12|2023-12-12 07:00:00|           5.9|\n",
      "|2023-12-12|2023-12-12 08:00:00|          NULL|\n",
      "|      NULL|               NULL|           6.1|\n",
      "|2023-12-12|2023-12-12 10:00:00|           6.1|\n",
      "|      NULL|               NULL|          NULL|\n",
      "|2023-12-12|2023-12-12 12:00:00|           6.5|\n",
      "|2023-12-12|2023-12-12 13:00:00|           6.7|\n",
      "|2023-12-12|2023-12-12 14:00:00|           6.7|\n",
      "|2023-12-12|2023-12-12 15:00:00|           6.5|\n",
      "|2023-12-12|2023-12-12 16:00:00|           6.1|\n",
      "|2023-12-12|2023-12-12 17:00:00|           5.7|\n",
      "|2023-12-12|2023-12-12 18:00:00|           5.2|\n",
      "|2023-12-12|2023-12-12 19:00:00|           4.5|\n",
      "+----------+-------------------+--------------+\n"
     ]
    }
   ],
   "source": [
    "df_spark = df_spark.drop('Temperature rise 2 degrees')\n",
    "df_spark.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T12:52:18.273536Z",
     "start_time": "2023-12-12T12:52:18.206886Z"
    }
   },
   "id": "388ed4fbedd96d2f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Zmiana nazwy kolumny"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "66ecd16156c7eac0"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "df_spark = df_spark.withColumnRenamed('time', 'date-time')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T12:52:46.137341Z",
     "start_time": "2023-12-12T12:52:46.126129Z"
    }
   },
   "id": "609e2b1886472ac2"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------------+--------------+\n",
      "|      date|          date-time|temperature_2m|\n",
      "+----------+-------------------+--------------+\n",
      "|2023-12-12|2023-12-12 00:00:00|           7.0|\n",
      "|2023-12-12|2023-12-12 01:00:00|           6.8|\n",
      "|2023-12-12|2023-12-12 02:00:00|           6.4|\n",
      "|2023-12-12|2023-12-12 03:00:00|           6.3|\n",
      "|2023-12-12|2023-12-12 04:00:00|           6.1|\n",
      "|2023-12-12|2023-12-12 05:00:00|           6.0|\n",
      "|2023-12-12|2023-12-12 06:00:00|           6.0|\n",
      "|2023-12-12|2023-12-12 07:00:00|           5.9|\n",
      "|2023-12-12|2023-12-12 08:00:00|          NULL|\n",
      "|      NULL|               NULL|           6.1|\n",
      "|2023-12-12|2023-12-12 10:00:00|           6.1|\n",
      "|      NULL|               NULL|          NULL|\n",
      "|2023-12-12|2023-12-12 12:00:00|           6.5|\n",
      "|2023-12-12|2023-12-12 13:00:00|           6.7|\n",
      "|2023-12-12|2023-12-12 14:00:00|           6.7|\n",
      "|2023-12-12|2023-12-12 15:00:00|           6.5|\n",
      "|2023-12-12|2023-12-12 16:00:00|           6.1|\n",
      "|2023-12-12|2023-12-12 17:00:00|           5.7|\n",
      "|2023-12-12|2023-12-12 18:00:00|           5.2|\n",
      "|2023-12-12|2023-12-12 19:00:00|           4.5|\n",
      "+----------+-------------------+--------------+\n"
     ]
    }
   ],
   "source": [
    "df_spark.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T12:52:47.016498Z",
     "start_time": "2023-12-12T12:52:46.953785Z"
    }
   },
   "id": "50fe0390469216e4"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------------+--------------+\n",
      "|      date|          date-time|temperature_2m|\n",
      "+----------+-------------------+--------------+\n",
      "|2023-12-12|2023-12-12 00:00:00|           7.0|\n",
      "|2023-12-12|2023-12-12 01:00:00|           6.8|\n",
      "|2023-12-12|2023-12-12 02:00:00|           6.4|\n",
      "|2023-12-12|2023-12-12 03:00:00|           6.3|\n",
      "|2023-12-12|2023-12-12 04:00:00|           6.1|\n",
      "|2023-12-12|2023-12-12 05:00:00|           6.0|\n",
      "|2023-12-12|2023-12-12 06:00:00|           6.0|\n",
      "|2023-12-12|2023-12-12 07:00:00|           5.9|\n",
      "|2023-12-12|2023-12-12 10:00:00|           6.1|\n",
      "|2023-12-12|2023-12-12 12:00:00|           6.5|\n",
      "|2023-12-12|2023-12-12 13:00:00|           6.7|\n",
      "|2023-12-12|2023-12-12 14:00:00|           6.7|\n",
      "|2023-12-12|2023-12-12 15:00:00|           6.5|\n",
      "|2023-12-12|2023-12-12 16:00:00|           6.1|\n",
      "|2023-12-12|2023-12-12 17:00:00|           5.7|\n",
      "|2023-12-12|2023-12-12 18:00:00|           5.2|\n",
      "|2023-12-12|2023-12-12 19:00:00|           4.5|\n",
      "|2023-12-12|2023-12-12 20:00:00|           4.1|\n",
      "|2023-12-12|2023-12-12 21:00:00|           4.0|\n",
      "|2023-12-12|2023-12-12 22:00:00|           3.9|\n",
      "+----------+-------------------+--------------+\n"
     ]
    }
   ],
   "source": [
    "# usuwanie wierszy z wartościami null\n",
    "df_spark.na.drop().show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T12:53:30.404341Z",
     "start_time": "2023-12-12T12:53:30.306738Z"
    }
   },
   "id": "943f74ce98732e62"
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------------+--------------+\n",
      "|      date|          date-time|temperature_2m|\n",
      "+----------+-------------------+--------------+\n",
      "|2023-12-12|2023-12-12 00:00:00|           7.0|\n",
      "|2023-12-12|2023-12-12 01:00:00|           6.8|\n",
      "|2023-12-12|2023-12-12 02:00:00|           6.4|\n",
      "|2023-12-12|2023-12-12 03:00:00|           6.3|\n",
      "|2023-12-12|2023-12-12 04:00:00|           6.1|\n",
      "|2023-12-12|2023-12-12 05:00:00|           6.0|\n",
      "|2023-12-12|2023-12-12 06:00:00|           6.0|\n",
      "|2023-12-12|2023-12-12 07:00:00|           5.9|\n",
      "|2023-12-12|2023-12-12 08:00:00|          NULL|\n",
      "|      NULL|               NULL|           6.1|\n",
      "|2023-12-12|2023-12-12 10:00:00|           6.1|\n",
      "|2023-12-12|2023-12-12 12:00:00|           6.5|\n",
      "|2023-12-12|2023-12-12 13:00:00|           6.7|\n",
      "|2023-12-12|2023-12-12 14:00:00|           6.7|\n",
      "|2023-12-12|2023-12-12 15:00:00|           6.5|\n",
      "|2023-12-12|2023-12-12 16:00:00|           6.1|\n",
      "|2023-12-12|2023-12-12 17:00:00|           5.7|\n",
      "|2023-12-12|2023-12-12 18:00:00|           5.2|\n",
      "|2023-12-12|2023-12-12 19:00:00|           4.5|\n",
      "|2023-12-12|2023-12-12 20:00:00|           4.1|\n",
      "+----------+-------------------+--------------+\n"
     ]
    }
   ],
   "source": [
    "# usuwanie tylko te wiersze, gdzie wszystkie wartości są null\n",
    "df_spark.na.drop(how='all').show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T12:54:00.657105Z",
     "start_time": "2023-12-12T12:54:00.569933Z"
    }
   },
   "id": "32ecd0f2ec713769"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------------+--------------+\n",
      "|      date|          date-time|temperature_2m|\n",
      "+----------+-------------------+--------------+\n",
      "|2023-12-12|2023-12-12 00:00:00|           7.0|\n",
      "|2023-12-12|2023-12-12 01:00:00|           6.8|\n",
      "|2023-12-12|2023-12-12 02:00:00|           6.4|\n",
      "|2023-12-12|2023-12-12 03:00:00|           6.3|\n",
      "|2023-12-12|2023-12-12 04:00:00|           6.1|\n",
      "|2023-12-12|2023-12-12 05:00:00|           6.0|\n",
      "|2023-12-12|2023-12-12 06:00:00|           6.0|\n",
      "|2023-12-12|2023-12-12 07:00:00|           5.9|\n",
      "|2023-12-12|2023-12-12 10:00:00|           6.1|\n",
      "|2023-12-12|2023-12-12 12:00:00|           6.5|\n",
      "|2023-12-12|2023-12-12 13:00:00|           6.7|\n",
      "|2023-12-12|2023-12-12 14:00:00|           6.7|\n",
      "|2023-12-12|2023-12-12 15:00:00|           6.5|\n",
      "|2023-12-12|2023-12-12 16:00:00|           6.1|\n",
      "|2023-12-12|2023-12-12 17:00:00|           5.7|\n",
      "|2023-12-12|2023-12-12 18:00:00|           5.2|\n",
      "|2023-12-12|2023-12-12 19:00:00|           4.5|\n",
      "|2023-12-12|2023-12-12 20:00:00|           4.1|\n",
      "|2023-12-12|2023-12-12 21:00:00|           4.0|\n",
      "|2023-12-12|2023-12-12 22:00:00|           3.9|\n",
      "+----------+-------------------+--------------+\n"
     ]
    }
   ],
   "source": [
    "# usuwa wiersze gdzie jest null\n",
    "df_spark.na.drop(how='any').show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T12:54:19.247074Z",
     "start_time": "2023-12-12T12:54:19.184575Z"
    }
   },
   "id": "186647dd86fc8a39"
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------------+--------------+\n",
      "|      date|          date-time|temperature_2m|\n",
      "+----------+-------------------+--------------+\n",
      "|2023-12-12|2023-12-12 00:00:00|           7.0|\n",
      "|2023-12-12|2023-12-12 01:00:00|           6.8|\n",
      "|2023-12-12|2023-12-12 02:00:00|           6.4|\n",
      "|2023-12-12|2023-12-12 03:00:00|           6.3|\n",
      "|2023-12-12|2023-12-12 04:00:00|           6.1|\n",
      "|2023-12-12|2023-12-12 05:00:00|           6.0|\n",
      "|2023-12-12|2023-12-12 06:00:00|           6.0|\n",
      "|2023-12-12|2023-12-12 07:00:00|           5.9|\n",
      "|2023-12-12|2023-12-12 08:00:00|          NULL|\n",
      "|2023-12-12|2023-12-12 10:00:00|           6.1|\n",
      "|2023-12-12|2023-12-12 12:00:00|           6.5|\n",
      "|2023-12-12|2023-12-12 13:00:00|           6.7|\n",
      "|2023-12-12|2023-12-12 14:00:00|           6.7|\n",
      "|2023-12-12|2023-12-12 15:00:00|           6.5|\n",
      "|2023-12-12|2023-12-12 16:00:00|           6.1|\n",
      "|2023-12-12|2023-12-12 17:00:00|           5.7|\n",
      "|2023-12-12|2023-12-12 18:00:00|           5.2|\n",
      "|2023-12-12|2023-12-12 19:00:00|           4.5|\n",
      "|2023-12-12|2023-12-12 20:00:00|           4.1|\n",
      "|2023-12-12|2023-12-12 21:00:00|           4.0|\n",
      "+----------+-------------------+--------------+\n"
     ]
    }
   ],
   "source": [
    "# threshold (przynajmniej 2 wartości null)\n",
    "df_spark.na.drop(how='any', thresh=2).show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T12:54:53.260735Z",
     "start_time": "2023-12-12T12:54:53.181638Z"
    }
   },
   "id": "a2a501245dcfe0f0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# subset\n",
    "df_spark.na.drop(how='any', thresh=1, subset=['temperature_2m']).show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c853ab0172046bcb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Uzupełnianie brakujących wartości"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bb2577be76fd408f"
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------------+--------------+\n",
      "|      date|          date-time|temperature_2m|\n",
      "+----------+-------------------+--------------+\n",
      "|2023-12-12|2023-12-12 00:00:00|           7.0|\n",
      "|2023-12-12|2023-12-12 01:00:00|           6.8|\n",
      "|2023-12-12|2023-12-12 02:00:00|           6.4|\n",
      "|2023-12-12|2023-12-12 03:00:00|           6.3|\n",
      "|2023-12-12|2023-12-12 04:00:00|           6.1|\n",
      "|2023-12-12|2023-12-12 05:00:00|           6.0|\n",
      "|2023-12-12|2023-12-12 06:00:00|           6.0|\n",
      "|2023-12-12|2023-12-12 07:00:00|           5.9|\n",
      "|2023-12-12|2023-12-12 08:00:00|         100.0|\n",
      "|      NULL|               NULL|           6.1|\n",
      "|2023-12-12|2023-12-12 10:00:00|           6.1|\n",
      "|      NULL|               NULL|         100.0|\n",
      "|2023-12-12|2023-12-12 12:00:00|           6.5|\n",
      "|2023-12-12|2023-12-12 13:00:00|           6.7|\n",
      "|2023-12-12|2023-12-12 14:00:00|           6.7|\n",
      "|2023-12-12|2023-12-12 15:00:00|           6.5|\n",
      "|2023-12-12|2023-12-12 16:00:00|           6.1|\n",
      "|2023-12-12|2023-12-12 17:00:00|           5.7|\n",
      "|2023-12-12|2023-12-12 18:00:00|           5.2|\n",
      "|2023-12-12|2023-12-12 19:00:00|           4.5|\n",
      "+----------+-------------------+--------------+\n"
     ]
    }
   ],
   "source": [
    "df_spark.na.fill(value=100, subset='temperature_2m').show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T12:56:17.543279Z",
     "start_time": "2023-12-12T12:56:17.436321Z"
    }
   },
   "id": "e481b92d59932bbe"
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------------+--------------+----------------------+\n",
      "|      date|          date-time|temperature_2m|temperature_2m_imputed|\n",
      "+----------+-------------------+--------------+----------------------+\n",
      "|2023-12-12|2023-12-12 00:00:00|           7.0|                   7.0|\n",
      "|2023-12-12|2023-12-12 01:00:00|           6.8|                   6.8|\n",
      "|2023-12-12|2023-12-12 02:00:00|           6.4|                   6.4|\n",
      "|2023-12-12|2023-12-12 03:00:00|           6.3|                   6.3|\n",
      "|2023-12-12|2023-12-12 04:00:00|           6.1|                   6.1|\n",
      "|2023-12-12|2023-12-12 05:00:00|           6.0|                   6.0|\n",
      "|2023-12-12|2023-12-12 06:00:00|           6.0|                   6.0|\n",
      "|2023-12-12|2023-12-12 07:00:00|           5.9|                   5.9|\n",
      "|2023-12-12|2023-12-12 08:00:00|          NULL|      5.23132530120482|\n",
      "|      NULL|               NULL|           6.1|                   6.1|\n",
      "|2023-12-12|2023-12-12 10:00:00|           6.1|                   6.1|\n",
      "|      NULL|               NULL|          NULL|      5.23132530120482|\n",
      "|2023-12-12|2023-12-12 12:00:00|           6.5|                   6.5|\n",
      "|2023-12-12|2023-12-12 13:00:00|           6.7|                   6.7|\n",
      "|2023-12-12|2023-12-12 14:00:00|           6.7|                   6.7|\n",
      "|2023-12-12|2023-12-12 15:00:00|           6.5|                   6.5|\n",
      "|2023-12-12|2023-12-12 16:00:00|           6.1|                   6.1|\n",
      "|2023-12-12|2023-12-12 17:00:00|           5.7|                   5.7|\n",
      "|2023-12-12|2023-12-12 18:00:00|           5.2|                   5.2|\n",
      "|2023-12-12|2023-12-12 19:00:00|           4.5|                   4.5|\n",
      "+----------+-------------------+--------------+----------------------+\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import Imputer\n",
    "\n",
    "imputer = Imputer(\n",
    "    inputCol='temperature_2m',\n",
    "    outputCol='temperature_2m_imputed'\n",
    ").setStrategy('mean')\n",
    "imputer.fit(df_spark).transform(df_spark).show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T12:57:13.348926Z",
     "start_time": "2023-12-12T12:57:13.023827Z"
    }
   },
   "id": "2eda05541b57d940"
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "ename": "IllegalArgumentException",
     "evalue": "requirement failed: Column date must be of type numeric but was actually of type date.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mIllegalArgumentException\u001B[0m                  Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[32], line 5\u001B[0m\n\u001B[1;32m      1\u001B[0m imputer \u001B[38;5;241m=\u001B[39m Imputer(\n\u001B[1;32m      2\u001B[0m     inputCols\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdate\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtemperature_2m\u001B[39m\u001B[38;5;124m'\u001B[39m],\n\u001B[1;32m      3\u001B[0m     outputCols\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mc\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m_imputed\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m c \u001B[38;5;129;01min\u001B[39;00m [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdate\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtemperature_2m\u001B[39m\u001B[38;5;124m'\u001B[39m]]\n\u001B[1;32m      4\u001B[0m )\u001B[38;5;241m.\u001B[39msetStrategy(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmean\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m----> 5\u001B[0m imputer\u001B[38;5;241m.\u001B[39mfit(df_spark)\u001B[38;5;241m.\u001B[39mtransform(df_spark)\u001B[38;5;241m.\u001B[39mshow()\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/pyspark_env/lib/python3.12/site-packages/pyspark/ml/base.py:205\u001B[0m, in \u001B[0;36mEstimator.fit\u001B[0;34m(self, dataset, params)\u001B[0m\n\u001B[1;32m    203\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcopy(params)\u001B[38;5;241m.\u001B[39m_fit(dataset)\n\u001B[1;32m    204\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 205\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fit(dataset)\n\u001B[1;32m    206\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    207\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\n\u001B[1;32m    208\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mParams must be either a param map or a list/tuple of param maps, \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    209\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbut got \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m \u001B[38;5;28mtype\u001B[39m(params)\n\u001B[1;32m    210\u001B[0m     )\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/pyspark_env/lib/python3.12/site-packages/pyspark/ml/wrapper.py:381\u001B[0m, in \u001B[0;36mJavaEstimator._fit\u001B[0;34m(self, dataset)\u001B[0m\n\u001B[1;32m    380\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_fit\u001B[39m(\u001B[38;5;28mself\u001B[39m, dataset: DataFrame) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m JM:\n\u001B[0;32m--> 381\u001B[0m     java_model \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fit_java(dataset)\n\u001B[1;32m    382\u001B[0m     model \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_create_model(java_model)\n\u001B[1;32m    383\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_copyValues(model)\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/pyspark_env/lib/python3.12/site-packages/pyspark/ml/wrapper.py:378\u001B[0m, in \u001B[0;36mJavaEstimator._fit_java\u001B[0;34m(self, dataset)\u001B[0m\n\u001B[1;32m    375\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_java_obj \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    377\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_transfer_params_to_java()\n\u001B[0;32m--> 378\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_java_obj\u001B[38;5;241m.\u001B[39mfit(dataset\u001B[38;5;241m.\u001B[39m_jdf)\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/pyspark_env/lib/python3.12/site-packages/py4j/java_gateway.py:1322\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m   1316\u001B[0m command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1317\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1318\u001B[0m     args_command \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1319\u001B[0m     proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n\u001B[1;32m   1321\u001B[0m answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39msend_command(command)\n\u001B[0;32m-> 1322\u001B[0m return_value \u001B[38;5;241m=\u001B[39m get_return_value(\n\u001B[1;32m   1323\u001B[0m     answer, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtarget_id, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mname)\n\u001B[1;32m   1325\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m temp_arg \u001B[38;5;129;01min\u001B[39;00m temp_args:\n\u001B[1;32m   1326\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(temp_arg, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_detach\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/pyspark_env/lib/python3.12/site-packages/pyspark/errors/exceptions/captured.py:185\u001B[0m, in \u001B[0;36mcapture_sql_exception.<locals>.deco\u001B[0;34m(*a, **kw)\u001B[0m\n\u001B[1;32m    181\u001B[0m converted \u001B[38;5;241m=\u001B[39m convert_exception(e\u001B[38;5;241m.\u001B[39mjava_exception)\n\u001B[1;32m    182\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(converted, UnknownException):\n\u001B[1;32m    183\u001B[0m     \u001B[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001B[39;00m\n\u001B[1;32m    184\u001B[0m     \u001B[38;5;66;03m# JVM exception message.\u001B[39;00m\n\u001B[0;32m--> 185\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m converted \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    186\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    187\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n",
      "\u001B[0;31mIllegalArgumentException\u001B[0m: requirement failed: Column date must be of type numeric but was actually of type date."
     ]
    }
   ],
   "source": [
    "imputer = Imputer(\n",
    "    inputCols=['date', 'temperature_2m'],\n",
    "    outputCols=[f'{c}_imputed' for c in ['date', 'temperature_2m']]\n",
    ").setStrategy('mean')\n",
    "imputer.fit(df_spark).transform(df_spark).show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T12:58:05.317368Z",
     "start_time": "2023-12-12T12:58:05.068882Z"
    }
   },
   "id": "c0622ee643736111"
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "spark.stop()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T12:58:29.369097Z",
     "start_time": "2023-12-12T12:58:29.029232Z"
    }
   },
   "id": "5b1f8e88bd655b19"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "acdd9b3fbb747a4f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
